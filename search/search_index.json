{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"screen_ocr","text":"<p>The <code>screen_ocr</code> repository provides a Python library for performing Optical Character Recognition (OCR) on screenshots. It supports multiple backends, including WinRT (Windows only), Tesseract, and EasyOCR, and it allows users to choose between speed and quality. The core logic is in the <code>screen_ocr</code> directory, while tests are in the <code>tests</code> directory.</p> <p>The library has the following dependencies:</p> <ul> <li><code>pillow</code>: Used for image processing.</li> <li><code>rapidfuzz</code>: Used for fuzzy string matching.</li> </ul> <p>The optional dependencies for different OCR backends are: *   <code>numpy</code>, <code>pytesseract</code>, <code>pandas</code>, and <code>scikit-image</code>: Required for the Tesseract backend. *   <code>winsdk</code>: Required for the WinRT backend. *   <code>easyocr</code>, and <code>numpy</code>: Required for the EasyOCR backend.</p> <p>The development dependencies are: *   <code>imagehash</code>: Used for comparing images. *   <code>pytest</code>: Used for running tests. *   <code>scikit-image</code>: Used for image processing in tests. *  <code>scikit-learn</code>: Used for parameter optimization.</p> <p>The main components are:</p> <ul> <li>The <code>.github</code> directory contains GitHub workflow configurations. The <code>workflows</code> subdirectory contains a workflow to deploy documentation generated by <code>repo-guide</code>.</li> <li>The <code>screen_ocr</code> directory contains the main implementation. The library's core functionality is found in <code>_screen_ocr.py</code>, which defines the <code>Reader</code> and <code>ScreenContents</code> classes. The <code>Reader</code> handles capturing screenshots, preprocessing images, dispatching to a backend, and returning results. The <code>ScreenContents</code> class stores the OCR results and provides methods for finding words. The <code>_base.py</code> file defines base classes for the different backend implementations. The supported backends are implemented in separate files: <code>_easyocr.py</code>, <code>_tesseract.py</code>, <code>_talon.py</code>, and <code>_winrt.py</code>. The <code>__init__.py</code> file makes the core classes available when importing the <code>screen_ocr</code> package, and <code>__main__.py</code> demonstrates a basic use case by running OCR on the entire screen.</li> <li>The <code>tests</code> directory contains tests. <code>screen_ocr_test.py</code> tests the <code>ScreenContents</code> class, specifically its string matching capabilities. <code>test_utils.py</code> defines helper functions, including an <code>OcrEstimator</code> that allows for parameter tuning of the OCR process. <code>test_utils_test.py</code> contains basic tests for the helper functions.</li> <li>The <code>.git-blame-ignore-revs</code> file contains a list of revisions to ignore when using <code>git blame</code>.</li> <li>The <code>.gitattributes</code> file configures how Git handles line endings.</li> <li>The <code>.gitignore</code> file specifies intentionally untracked files that Git should ignore.</li> <li>The <code>.pre-commit-config.yaml</code> file configures pre-commit hooks, which runs <code>ruff</code>, a linter and formatter, before committing.</li> <li>The <code>.python-version</code> file specifies the Python version for the project.</li> <li>The <code>LICENSE</code> file contains the Apache 2.0 license.</li> <li>The <code>pyproject.toml</code> file specifies project metadata, dependencies, and build system settings.</li> <li>The <code>README.md</code> file provides an overview of the project, installation instructions, and basic usage examples.</li> <li>The <code>screen_ocr_tool.py</code> script provides an interface for debugging and grid searching to fine-tune OCR parameters. It loads images and ground truth text from the local <code>logs</code> directory and uses <code>scikit-learn</code> to optimize settings.</li> </ul> <p>The workflow for using this library typically involves:</p> <ol> <li>Installing the library and a backend (WinRT, Tesseract, or EasyOCR).</li> <li>Creating a <code>Reader</code> instance using one of the class methods in <code>screen_ocr/_screen_ocr.py</code>.</li> <li>Calling the <code>read_image</code> or <code>read_screen</code> methods of the <code>Reader</code> to perform OCR.</li> <li>Using the returned <code>ScreenContents</code> object to access the OCR text, bounding boxes, and other information.</li> </ol> <p>The library's design allows for easy extension with new OCR backends by implementing the <code>OcrBackend</code> interface in <code>screen_ocr/_base.py</code>. The test suite uses a parameter optimization approach, as demonstrated in <code>screen_ocr_tool.py</code>, enabling developers to fine-tune the OCR process for specific use cases.</p>"},{"location":".github/","title":".github","text":"<p>The <code>screen_ocr/.github</code> directory contains configuration for GitHub.</p> <p>The <code>workflows</code> subdirectory contains configuration files for GitHub Actions workflows. These workflows automate tasks related to the repository, such as building, testing, and deploying the documentation site.</p> <p>The <code>deploy_repo_guide.yml</code> file defines a workflow named \"Publish documentation generated by repo-guide\". This workflow is triggered manually via the \"workflow_dispatch\" event. It has <code>contents: write</code> permissions, allowing it to make changes to the repository. The workflow has a single job, <code>deploy</code>, which runs on an <code>ubuntu-latest</code> runner. The job first checks out the repository using the <code>actions/checkout@v4</code> action. It then uses the <code>wolfmanstout/deploy-repo-guide@v1</code> action to deploy the documentation generated by <code>repo-guide</code>. The <code>gemini-key</code> input to this action is set using a secret, <code>LLM_GEMINI_KEY</code>.</p>"},{"location":".github/workflows/","title":"workflows","text":"<p>The <code>screen_ocr/.github/workflows</code> directory contains configuration files for GitHub Actions workflows. These workflows automate tasks related to the repository, such as building, testing, and deploying the documentation site.</p> <p>The <code>deploy_repo_guide.yml</code> file defines a workflow named \"Publish documentation generated by repo-guide\". This workflow is triggered manually via the \"workflow_dispatch\" event. It has <code>contents: write</code> permissions, allowing it to make changes to the repository. The workflow has a single job, <code>deploy</code>, which runs on an <code>ubuntu-latest</code> runner. The job first checks out the repository using the <code>actions/checkout@v4</code> action. It then uses the <code>wolfmanstout/deploy-repo-guide@v1</code> action to deploy the documentation generated by <code>repo-guide</code>. The <code>gemini-key</code> input to this action is set using a secret, <code>LLM_GEMINI_KEY</code>.</p>"},{"location":"screen_ocr/","title":"screen_ocr","text":"<p>The <code>screen_ocr</code> directory contains the core logic for the screen-ocr library. It provides a flexible interface for performing OCR on screenshots, using multiple backend OCR engines.</p> <p>The core functionality is exposed through the <code>Reader</code> class in <code>_screen_ocr.py</code>. This class is responsible for:</p> <ul> <li>Capturing screenshots using platform-specific methods.</li> <li>Preprocessing the images to improve OCR accuracy, such as resizing, adding margins, and thresholding.</li> <li>Dispatching the image to a specified backend for OCR.</li> <li>Returning the OCR results, which include the text, bounding boxes, and other metadata needed for downstream processing.</li> </ul> <p>The <code>Reader</code> class has several class methods for creating a reader with different settings:</p> <ul> <li><code>create_quality_reader</code>     Creates a reader that prioritizes quality of the OCR results, using the WinRT backend if available, or Tesseract otherwise.</li> <li><code>create_fast_reader</code>     Creates a reader optimized for speed, using the WinRT backend if available, or Tesseract otherwise. This reader uses more aggressive preprocessing settings.</li> <li><code>create_reader</code>     Creates a reader with a specified backend and settings.</li> </ul> <p>The <code>ScreenContents</code> class, also in <code>_screen_ocr.py</code>, holds the OCR results and provides methods for finding words, calculating distances, and converting the results into text. It includes logic for fuzzy matching, homophone handling, and searching within a specified radius. The <code>WordLocation</code> dataclass stores the location and text of an individual word in the OCR result.</p> <p>The library supports multiple OCR backends. The following backends are implemented:</p> <ul> <li><code>_base.py</code> defines base classes (<code>OcrBackend</code>, <code>OcrResult</code>, <code>OcrLine</code>, <code>OcrWord</code>) used by the backend implementations.</li> <li><code>_easyocr.py</code> provides an implementation using the easyocr library.</li> <li><code>_tesseract.py</code> provides an implementation using the Tesseract OCR engine.</li> <li><code>_talon.py</code> provides an implementation using the OCR functionality in the Talon voice control system.</li> <li><code>_winrt.py</code> provides an implementation using the Windows Runtime OCR engine.</li> </ul> <p>The <code>__init__.py</code> file simply imports everything from <code>_screen_ocr.py</code>, making the core classes available directly when importing the <code>screen_ocr</code> package.</p> <p>The <code>__main__.py</code> file demonstrates a basic use case by creating a quality reader and printing the OCR results of the entire screen, which can be run from the command line using <code>python -m screen_ocr</code>.</p>"},{"location":"tests/","title":"tests","text":"<p>The <code>screen_ocr/tests</code> directory contains tests for the <code>screen_ocr</code> package.</p> <p><code>screen_ocr_test.py</code> contains tests for the <code>screen_ocr</code> module. The tests focus on the <code>ScreenContents</code> class, specifically testing the <code>find_longest_matching_suffix</code> and <code>_generate_candidates_from_line</code> methods. The <code>find_longest_matching_suffix</code> method appears to find the longest suffix of a given string within the <code>ScreenContents</code> object, which is used to represent the contents of a screen detected by OCR. The <code>_generate_candidates_from_line</code> method generates word location candidates from a line of OCR output, attempting to split camel case, snake case, and other multi-word strings.</p> <p><code>test_utils.py</code> defines helper functions and classes for testing the OCR functionality. It includes a <code>cost</code> function that computes a score between the OCR result and the ground truth using <code>rapidfuzz.fuzz.partial_ratio</code>, and an <code>OcrEstimator</code> class that is a scikit-learn compatible estimator, which allows the different OCR parameters to be easily tested using <code>scikit-learn</code>'s utilities for cross-validation and parameter optimization. The <code>OcrEstimator</code>'s <code>fit</code> method constructs an <code>screen_ocr.Reader</code> using a variety of pre-processing and OCR configuration parameters, such as thresholding, image resizing, channel shifting, and component labeling. The <code>score</code> method uses the configured reader to read text from provided images and calculate the cost (or error) based on the ground truth text.</p> <p><code>test_utils_test.py</code> contains a basic test case for the <code>cost</code> function defined in <code>test_utils.py</code>. It uses <code>unittest</code> to assert that strings with better matches have a lower cost.</p>"}]}