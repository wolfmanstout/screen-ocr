{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"screen_ocr","text":"<p>The <code>screen_ocr</code> repository provides a Python library for performing Optical Character Recognition (OCR) on screen captures or images. It supports multiple backends, including WinRT (Windows only), Tesseract (cross-platform), and EasyOCR (experimental). The library is designed to be extensible, allowing for the addition of new OCR backends.</p> <p>The core functionality of the library is in the <code>screen_ocr/screen_ocr</code> directory, which exposes a <code>Reader</code> class used to perform OCR, and a <code>ScreenContents</code> class to analyze the output. The <code>tests</code> directory includes unit tests and a scikit-learn compatible estimator to evaluate the various OCR options.</p> <p>The main dependencies are:</p> <ul> <li>Pillow: Used for image processing, such as resizing and format conversion.</li> <li>rapidfuzz: Used for fuzzy string matching when searching for text within the OCR results.</li> <li>Optional Dependencies:<ul> <li>numpy: Required for Tesseract and EasyOCR backends.</li> <li>pytesseract:  Used for the Tesseract OCR backend.</li> <li>pandas: Used by Tesseract backend to load language data.</li> <li>scikit-image: Used by Tesseract backend for image preprocessing.</li> <li>winsdk: Used for the WinRT OCR backend.</li> <li>easyocr: Used for the EasyOCR backend.</li> </ul> </li> <li>Development Dependencies<ul> <li>imagehash: Used in <code>screen_ocr_tool.py</code> to determine near-duplicate images during OCR evaluation.</li> <li>pytest: Used for running unit tests.</li> <li>scikit-learn: Used for creating the <code>OcrEstimator</code> which evaluates OCR performance.</li> </ul> </li> </ul> <p>The main components of the repository and how they work together:</p> <ul> <li>The <code>screen_ocr</code> directory contains the core logic of the library.<ul> <li><code>screen_ocr/_base.py</code> defines the base classes for the library: <code>OcrWord</code>, <code>OcrLine</code>, <code>OcrResult</code>, and <code>OcrBackend</code>.</li> <li><code>screen_ocr/_screen_ocr.py</code> defines the <code>Reader</code> class, which is responsible for taking screenshots, preprocessing images, running OCR using a backend, and returning the results as a <code>ScreenContents</code> object. The <code>ScreenContents</code> class provides methods for searching, extracting, and locating words in the screen capture.</li> <li><code>screen_ocr/_easyocr.py</code>, <code>screen_ocr/_talon.py</code>, <code>screen_ocr/_tesseract.py</code>, and <code>screen_ocr/_winrt.py</code> implement the <code>OcrBackend</code> interface using different OCR engines.</li> <li><code>screen_ocr/__init__.py</code> makes the library's core classes available directly from the <code>screen_ocr</code> package.</li> <li><code>screen_ocr/__main__.py</code> provides a command-line interface to perform OCR on the current screen.</li> </ul> </li> <li>The <code>tests</code> directory contains tests for the <code>screen_ocr</code> library.<ul> <li><code>tests/screen_ocr_test.py</code> contains unit tests for the <code>ScreenContents</code> class, ensuring that text searching and candidate generation work as expected.</li> <li><code>tests/test_utils.py</code> defines utility functions for testing, including a <code>cost</code> function that calculates how well an OCR result matches a target string, and an <code>OcrEstimator</code> class that allows training and evaluation of the OCR reader with different preprocessing and backend options.</li> <li><code>tests/test_utils_test.py</code> contains unit tests for the <code>cost</code> function defined in <code>test_utils.py</code>.</li> </ul> </li> <li>The <code>screen_ocr_tool.py</code> script is used for debugging and evaluating OCR performance, by running OCR on a set of images and comparing the result to a ground truth text file.</li> <li>The <code>.github</code> directory contains GitHub workflow configurations.<ul> <li>The <code>deploy_repo_guide.yml</code> workflow is used to deploy documentation generated by <code>repo-guide</code>.</li> </ul> </li> <li>Other files in the repository:<ul> <li><code>.git-blame-ignore-revs</code> specifies revisions to ignore when using <code>git blame</code>.</li> <li><code>.gitattributes</code> specifies how line endings should be handled by git.</li> <li><code>.gitignore</code> specifies files that should not be tracked by git.</li> <li><code>.pre-commit-config.yaml</code> configures pre-commit hooks that format code with ruff.</li> <li><code>.python-version</code> specifies the Python version used for development.</li> <li><code>LICENSE</code> contains the Apache License version 2.0.</li> <li><code>pyproject.toml</code> defines project metadata and build system requirements.</li> <li><code>README.md</code> provides basic information about the library.</li> </ul> </li> </ul> <p>In summary, the <code>screen_ocr</code> repository provides a modular and flexible library for performing screen OCR with several backend options, extensive unit tests and evaluation capabilities, and GitHub Actions for documentation deployment.</p>"},{"location":"_github/","title":".github","text":"<p>The <code>screen_ocr/.github</code> directory contains configuration files for GitHub features.</p> <p>The workflows subdirectory contains GitHub Actions workflow files. These files automate tasks related to the repository.</p> <p>The <code>deploy_repo_guide.yml</code> file defines a workflow that publishes documentation generated by <code>repo-guide</code>. This workflow is manually triggered, requires write permissions, runs on an Ubuntu runner, checks out the repository, and then executes the <code>wolfmanstout/deploy-repo-guide@v1</code> action. The action uses a Gemini API key stored as a secret named <code>LLM_GEMINI_KEY</code>.</p>"},{"location":"_github/workflows/","title":"workflows","text":"<p>The <code>screen_ocr/.github/workflows</code> directory contains GitHub Actions workflow files. These files automate tasks related to the repository.</p> <p>The <code>deploy_repo_guide.yml</code> file defines a workflow that publishes documentation generated by <code>repo-guide</code>. This workflow is manually triggered, requires write permissions, runs on an Ubuntu runner, checks out the repository, and then executes the <code>wolfmanstout/deploy-repo-guide@v1</code> action. The action uses a Gemini API key stored as a secret named <code>LLM_GEMINI_KEY</code>.</p>"},{"location":"screen_ocr/","title":"screen_ocr","text":"<p>The <code>screen_ocr</code> directory contains the core logic for the screen-ocr library. It provides an interface for performing OCR on a screen or image, along with implementations for several OCR backends.</p> <p>Here's a breakdown of the key files and how they work together:</p> <ul> <li> <p><code>_base.py</code>: This file defines the base classes for the library: <code>OcrWord</code>, <code>OcrLine</code>, <code>OcrResult</code>, and <code>OcrBackend</code>. These classes provide a common interface that different OCR backends can implement. The data classes <code>OcrWord</code>, <code>OcrLine</code>, and <code>OcrResult</code> define the data structure used to store results of OCR, and the <code>OcrBackend</code> abstract class defines the <code>run_ocr</code> method.</p> </li> <li> <p><code>_screen_ocr.py</code>: This file contains the main logic for the library. It defines the <code>Reader</code> class, which is responsible for taking screenshots, preprocessing images, running OCR using a backend, and returning the OCR results in a structured format (<code>ScreenContents</code>). The <code>ScreenContents</code> class contains the OCR results and provides functionality to search for text, extract text, and find locations of words in the image. The <code>Reader</code> class can be created with different backends for different operating systems and desired OCR speed/quality tradeoffs.</p> <p>The <code>Reader</code> class provides the following key functionalities: *   <code>create_quality_reader</code>: Creates a reader optimized for quality. *   <code>create_fast_reader</code>: Creates a reader optimized for speed. *   <code>create_reader</code>: Creates a reader with a specified backend. *   <code>read_nearby</code>: Reads text from a region surrounding a given coordinate. *   <code>read_screen</code>: Reads text from the entire screen. *   <code>read_current_window</code>: Reads text from the active window (Talon backend only). *   <code>read_image</code>: Reads text from a given image.</p> <p>The <code>ScreenContents</code> class provides the following key functionalities: *   <code>as_string</code>: Returns the OCR'd text as a single string. *  <code>cropped</code>: Returns a new <code>ScreenContents</code> object that is cropped to a given bounding box. *  <code>find_nearest_word_coordinates</code>: Returns the coordinates of the nearest instance of a target word, using fuzzy matching. *  <code>find_nearest_word</code>: Returns the <code>WordLocation</code> of the nearest instance of a target word, using fuzzy matching. *  <code>find_nearest_words</code>: Returns the <code>WordLocation</code>s of the nearest instance of a sequence of target words, using fuzzy matching. * <code>find_longest_matching_prefix</code>: Returns the <code>WordLocation</code>s of the longest matching prefix of the target string using fuzzy matching. * <code>find_longest_matching_suffix</code>: Returns the <code>WordLocation</code>s of the longest matching suffix of the target string using fuzzy matching. * <code>find_matching_words</code>: Returns the <code>WordLocation</code>s of all matching instances of the target string using fuzzy matching.</p> </li> <li> <p>Backend implementations:</p> <ul> <li><code>_easyocr.py</code>: Implements the <code>OcrBackend</code> interface using the <code>easyocr</code> library. It initializes <code>easyocr</code> and uses it to run the OCR on a given image.</li> <li><code>_talon.py</code>: Implements the <code>OcrBackend</code> interface using the Talon's experimental <code>ocr</code> module.</li> <li><code>_tesseract.py</code>: Implements the <code>OcrBackend</code> interface using the <code>pytesseract</code> library, which is a wrapper for the Tesseract OCR engine. The Tesseract backend provides methods for image preprocessing, including thresholding and channel shifting.</li> <li><code>_winrt.py</code>: Implements the <code>OcrBackend</code> interface using the Windows Runtime (WinRT) OCR API. This backend is only available on Windows and provides high-quality, fast OCR.</li> </ul> </li> <li><code>__init__.py</code>: This file makes the classes and functions defined in <code>_screen_ocr.py</code> directly available when the <code>screen_ocr</code> package is imported.</li> <li><code>__main__.py</code>: This file provides a simple script that can be run to perform OCR on the current screen contents and print the results. This file allows you to quickly test the OCR functionality using the command <code>python -m screen_ocr</code>.</li> </ul> <p>In summary, the <code>screen_ocr</code> directory provides a flexible and extensible framework for performing screen OCR. The <code>_screen_ocr.py</code> file defines the core logic and interface, while the other files provide different backend implementations. The library can be used to read text from the entire screen, a specific region, or a given image. The library also provides methods for searching, extracting, and finding the location of words on the screen.</p>"},{"location":"tests/","title":"tests","text":"<p>The <code>screen_ocr/tests</code> directory contains the tests for the <code>screen_ocr</code> library. These tests are crucial for ensuring the library functions as expected and for demonstrating how to use its various features.</p> <p>Here's a breakdown of the key files:</p> <ul> <li> <p><code>screen_ocr_test.py</code>: This file contains the core unit tests for the <code>screen_ocr</code> library.  It focuses on testing the functionality of <code>ScreenContents</code>, specifically how it locates text within a screen capture and generates search candidates.</p> <ul> <li><code>test_find_longest_matching_suffix</code> tests the <code>find_longest_matching_suffix</code> method of the <code>ScreenContents</code> class. This method is used to locate the longest suffix of a search string within the text extracted from a screenshot. It checks that the correct word locations and suffix lengths are returned.</li> <li><code>test_generate_candidates_from_line</code> tests the <code>_generate_candidates_from_line</code> method of the <code>ScreenContents</code> class. This method is responsible for breaking down the text extracted from a line of OCR into a list of potential search candidates by splitting on whitespace, camel case, snake case, etc. It verifies that all expected candidates are generated with the correct character offsets and associated data.</li> </ul> </li> <li> <p><code>test_utils.py</code>: This file defines utility classes and functions used in testing the OCR library.</p> <ul> <li>The <code>cost</code> function calculates a cost based on the partial ratio between the extracted text and ground truth using <code>rapidfuzz</code>. It is used as a scoring function in the scikit-learn estimator to quantify how closely an OCR result matches a target string. This is used to evaluate the performance of various OCR configurations.</li> <li>The <code>OcrEstimator</code> class is a scikit-learn compatible estimator that encapsulates the <code>screen_ocr.Reader</code>. It allows training and evaluation of the OCR reader with different preprocessing and backend options. The <code>fit</code> method configures the <code>screen_ocr.Reader</code> using different thresholding techniques such as Otsu, local Otsu, Niblack, and Sauvola. The <code>score</code> method evaluates the reader by calculating the total <code>cost</code> of the OCR results against ground truth text.</li> </ul> </li> <li> <p><code>test_utils_test.py</code>: This file contains unit tests specifically for the functions defined in <code>test_utils.py</code>. It primarily tests the <code>cost</code> function, ensuring that it correctly scores strings based on partial matching using <code>rapidfuzz</code>.</p> </li> </ul> <p>These test files collectively demonstrate how to test the core functionality of <code>screen_ocr</code> using unit tests and using a scikit-learn compatible interface. They ensure that the library is robust, accurate, and usable.</p>"}]}