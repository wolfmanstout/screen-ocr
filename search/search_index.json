{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"screen_ocr","text":"<p>The <code>screen_ocr</code> repository contains a Python library for performing Optical Character Recognition (OCR) on screen captures. It supports multiple OCR backends, including WinRT (Windows only), Tesseract, and EasyOCR. The library is designed to be flexible, allowing users to choose the backend that best suits their needs based on accuracy, speed, and platform compatibility.</p> <p>The core functionality is implemented in the <code>screen_ocr</code> subdirectory. The <code>_screen_ocr.py</code> file provides a <code>Reader</code> class for capturing screenshots, running OCR, and searching for text within the results. It uses the backend-specific classes found in files such as <code>_easyocr.py</code>, <code>_tesseract.py</code>, <code>_talon.py</code>, and <code>_winrt.py</code>. The <code>Reader</code> class offers different methods for creating readers optimized for speed or accuracy. The <code>ScreenContents</code> class provides methods for searching and extracting text from the OCR results.</p> <p>The repository also includes a comprehensive test suite in the <code>tests</code> directory. The <code>screen_ocr_test.py</code> file verifies the core functionality, while <code>test_utils.py</code> provides testing utilities, including an estimator class for evaluating OCR accuracy.</p> <p>The main dependencies are:</p> <ul> <li><code>pillow</code> is used for image manipulation.</li> <li><code>rapidfuzz</code> is used for fuzzy string matching.</li> <li><code>numpy</code> is used by Tesseract and EasyOCR for numerical operations.</li> <li><code>pytesseract</code> is a wrapper around the Tesseract OCR engine.</li> <li><code>pandas</code> is used in the Tesseract backend for data manipulation.</li> <li><code>scikit-image</code> is used in the Tesseract backend for image preprocessing.</li> <li><code>winsdk</code> is a dependency for the WinRT backend.</li> <li><code>easyocr</code> is used for the EasyOCR backend.</li> </ul> <p>The repository uses <code>pre-commit</code> to manage code quality. It uses <code>ruff</code> for linting and formatting via <code>.pre-commit-config.yaml</code>.</p> <ul> <li>The <code>.git-blame-ignore-revs</code> file specifies a commit that should be ignored when using <code>git blame</code>.</li> <li>The <code>.gitattributes</code> file configures how line endings should be handled by Git.</li> <li>The <code>.gitignore</code> file specifies which files and directories should be ignored by Git.</li> <li>The <code>.python-version</code> file specifies the Python version used by the project.</li> <li>The <code>LICENSE</code> file contains the Apache 2.0 license.</li> <li>The <code>pyproject.toml</code> file specifies the project metadata, dependencies, and build system.</li> <li>The <code>README.md</code> file contains a description of the project and instructions for installation and usage.</li> <li>The <code>screen_ocr_tool.py</code> provides a tool for running OCR and evaluating performance.</li> </ul> <p>The <code>screen_ocr_tool.py</code> file is primarily used for debugging and performance evaluation of the OCR library. It loads image and text data from specified directories, performs OCR, and calculates a cost based on the similarity between the OCR results and the ground truth text. It can operate in either <code>debug</code> or <code>grid_search</code> mode.</p> <p>The <code>grid_search</code> mode uses a <code>scikit-learn</code> estimator (<code>test_utils.OcrEstimator</code>) to perform a grid search over different preprocessing parameters and OCR backends to identify the optimal settings. The parameters include backend type, resize factor and method, and whether or not to convert to grayscale or shift channels. The <code>debug</code> mode allows you to manually evaluate the performance on a set of specific images and settings.</p>"},{"location":"_github/","title":".github","text":"<p>The <code>screen_ocr/.github</code> directory contains configuration files for GitHub.</p> <p>The <code>workflows</code> subdirectory contains GitHub Actions workflows. The most important is <code>deploy_repo_guide.yml</code>.</p> <p>The <code>deploy_repo_guide.yml</code> workflow automates the generation and deployment of documentation for the repository. It is triggered manually and uses the <code>wolfmanstout/deploy-repo-guide</code> action, which likely leverages a Large Language Model (LLM) API key stored in repository secrets to generate the documentation. The workflow checks out the repository and then executes the <code>deploy-repo-guide</code> action, passing in the <code>LLM_GEMINI_KEY</code>.</p>"},{"location":"_github/workflows/","title":"workflows","text":"<p>The <code>screen_ocr/.github/workflows</code> directory contains GitHub Actions workflows, which automate tasks within the repository.</p> <p>The <code>deploy_repo_guide.yml</code> workflow is triggered manually and publishes documentation generated by the <code>wolfmanstout/deploy-repo-guide</code> action. This action likely uses the LLM (Large Language Model) API key found in the repository secrets to generate documentation. The workflow checks out the repository, then runs the <code>deploy-repo-guide</code> action, passing in the <code>LLM_GEMINI_KEY</code>. This action will then generate and deploy documentation based on the current state of the repository.</p>"},{"location":"screen_ocr/","title":"screen_ocr","text":"<p>The <code>screen_ocr</code> directory contains the core logic for the screen-ocr library. It defines the classes for performing OCR on screen captures, as well as the various OCR backends used.</p> <p>The file _base.py defines the base classes used by the various OCR backend implementations. It includes dataclasses <code>OcrWord</code>, <code>OcrLine</code>, and <code>OcrResult</code> to represent the output of an OCR operation, and an abstract base class <code>OcrBackend</code> that defines the interface for any concrete OCR backend.</p> <p>Several files define concrete implementations of the <code>OcrBackend</code> class:</p> <ul> <li>_easyocr.py implements an OCR backend using the <code>easyocr</code> library.</li> <li>_tesseract.py implements an OCR backend using the <code>pytesseract</code> library, which is a wrapper around the Tesseract OCR engine. This backend includes image preprocessing logic such as thresholding and channel shifting to improve accuracy.</li> <li>_talon.py implements an OCR backend using the <code>talon</code> library. This backend is designed to be used within the Talon voice control system. It tightens bounding boxes around detected words using image processing.</li> <li>_winrt.py implements an OCR backend using the Windows Runtime (WinRT) OCR API. It runs all interactions with WinRT on a separate thread, as is required by the API.</li> </ul> <p>The primary file for users of this library is _screen_ocr.py. It contains the <code>Reader</code> class, which is responsible for coordinating the overall OCR process. It chooses the appropriate OCR backend, captures screenshots, preprocesses images, and post-processes the results to return structured text data. It also contains the <code>ScreenContents</code> class, which represents the results of an OCR operation and provides methods for searching for text within the captured screen region using fuzzy matching, as well as extracting words or sequences of words, including nearest matches.</p> <p>The <code>Reader</code> class has several static methods for creating reader instances with different configurations:</p> <ul> <li><code>create_quality_reader</code>: Creates a reader optimized for accuracy, using the WinRT backend when available, and falling back to tesseract.</li> <li><code>create_fast_reader</code>: Creates a reader optimized for speed, using the WinRT backend when available, and falling back to tesseract with modified preprocessing parameters.</li> <li><code>create_reader</code>: Creates a reader with a specific backend and configuration.</li> </ul> <p>The <code>Reader</code> class also has methods for performing OCR on different regions of the screen:</p> <ul> <li><code>read_nearby</code>: Reads a rectangular region around a specified coordinate.</li> <li><code>read_screen</code>: Reads the entire screen, or a specific bounding box if provided.</li> <li><code>read_current_window</code>: Reads the contents of the current active window when using the Talon backend.</li> <li><code>read_image</code>: Performs OCR on a pre-captured image.</li> </ul> <p>The <code>ScreenContents</code> class provides a number of methods for analyzing the OCR results:</p> <ul> <li><code>as_string</code>: Returns the OCR'd text as a string.</li> <li><code>cropped</code>: Returns a new <code>ScreenContents</code> object cropped to a given bounding box.</li> <li><code>find_nearest_word_coordinates</code>: Returns the coordinates of the nearest matching word, with an option for where to put the coordinates relative to the word (\"before\", \"middle\", or \"after\").</li> <li><code>find_nearest_word</code>: Returns the <code>WordLocation</code> of the nearest matching word.</li> <li><code>find_nearest_words</code>: Returns the <code>WordLocation</code>s of the nearest matching sequence of words.</li> <li><code>find_matching_words</code>: Returns the <code>WordLocation</code>s of all matching sequences of words.</li> <li><code>find_longest_matching_prefix</code>: Returns the locations of the longest matching prefix of a sequence of words.</li> <li><code>find_longest_matching_suffix</code>: Returns the locations of the longest matching suffix of a sequence of words.</li> </ul> <p>The file <code>__init__.py</code> makes the contents of <code>_screen_ocr.py</code> available at the top level of the <code>screen_ocr</code> package.</p> <p>The file <code>__main__.py</code> provides a simple command-line interface for performing OCR on the current screen and printing the results to standard output.</p>"},{"location":"tests/","title":"tests","text":"<p>The <code>screen_ocr/tests</code> directory contains unit tests for the screen-ocr library. It includes tests for core functionality as well as utilities used in testing.</p> <ul> <li> <p><code>screen_ocr_test.py</code> contains tests for the main <code>screen_ocr</code> module. The tests verify the logic of finding the longest matching suffix of a string within OCR results and generating candidate word locations from OCR lines. These are key features for locating text on the screen.</p> <ul> <li><code>test_find_longest_matching_suffix</code> tests that <code>ScreenContents.find_longest_matching_suffix()</code> correctly identifies the longest suffix of a search string present in the OCR result. It also ensures that it returns the correct locations within the result.</li> <li><code>test_generate_candidates_from_line</code> tests that <code>ScreenContents._generate_candidates_from_line()</code> correctly generates word location candidates from an OCR line. It ensures that the correct text, offsets, and bounding boxes are returned for each candidate. It splits camel case, snake case, and other common casing conventions into individual words.</li> </ul> </li> <li> <p><code>test_utils.py</code> provides utility classes and functions for testing the OCR functionality, including a custom estimator class and a cost function.</p> <ul> <li>The <code>cost</code> function calculates a score based on string similarity using <code>rapidfuzz.fuzz.partial_ratio</code>. It penalizes strings that don't have a high degree of similarity with the ground truth text, and it is used to evaluate the quality of OCR results.</li> <li>The <code>OcrEstimator</code> class is a scikit-learn estimator that wraps the <code>screen_ocr.Reader</code> class. It handles different preprocessing steps (thresholding, resizing, grayscale conversion, channel shifting and component labeling) before performing OCR. It is used to automatically evaluate how different settings impact OCR accuracy.</li> </ul> </li> <li> <p><code>test_utils_test.py</code> contains tests for the utilities defined in <code>test_utils.py</code>.</p> <ul> <li><code>TestUtilsTestCase.test_cost</code> verifies the <code>cost</code> function by comparing similarity scores between different strings. It ensures the function gives higher scores to strings that are more similar to the ground truth.</li> </ul> </li> </ul>"}]}